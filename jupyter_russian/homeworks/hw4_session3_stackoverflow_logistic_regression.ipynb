{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)\n",
      "system     : Darwin\n",
      "release    : 17.4.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 6b51138cd7370803455c3e00fec8f41b69959ee8\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '/Users/ilyas/Documents/Innopolis/AI_com/datasets/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '/Users/ilyas/Documents/Innopolis/AI_com/datasets/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android', 'ios', 'python', 'jquery', 'html', 'c++', 'c#', 'php', 'javascript', 'java'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else 1 - 1/(1 + np.exp(z))\n",
    " \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += -y*np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                   -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6f31dff1e0448b93a5e7df7d521a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1162a7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.65\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        accuracy = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                pred_tags = None\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else 1 - 1/(1 + np.exp(z))\n",
    " \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += -y*np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                   -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if pred_tags is None:\n",
    "                            pred_tags = []\n",
    "                        if sigma > accuracy_level:\n",
    "                            pred_tags.append(tag)\n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "                if pred_tags is not None:\n",
    "                    accuracy.append(len(tags.intersection(pred_tags))/len(tags.union(pred_tags)))\n",
    "        return(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de082079984e44f08787eb8878342ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        accuracy = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                pred_tags = None\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else 1 - 1/(1 + np.exp(z))\n",
    " \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += -y*np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                   -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw \\\n",
    "                            + learning_rate*lmbda*self._w[tag][self._vocab[word]] \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if pred_tags is None:\n",
    "                            pred_tags = []\n",
    "                        if sigma > accuracy_level:\n",
    "                            pred_tags.append(tag)\n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "                if pred_tags is not None:\n",
    "                    accuracy.append(len(tags.intersection(pred_tags))/len(tags.union(pred_tags)))\n",
    "        return(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f2312cde234cb0b3fabbfbffc031bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.53\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1366f69e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     accuracy_level=0.9,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        accuracy = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "                pred_tags = None\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    \n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else 1 - 1/(1 + np.exp(z))\n",
    " \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss += -y*np.log(np.max([tolerance, sigma])) if y == 1 else \\\n",
    "                                   -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw \\\n",
    "                                                               + learning_rate*lmbda*gamma*self._w[tag][self._vocab[word]]/2 \\\n",
    "                                                               + learning_rate*lmbda*(1 - gamma)*np.sign(self._w[tag][self._vocab[word]])\n",
    "                    else:\n",
    "                        if pred_tags is None:\n",
    "                            pred_tags = []\n",
    "                        if sigma > accuracy_level:\n",
    "                            pred_tags.append(tag)\n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "                if pred_tags is not None:\n",
    "                    accuracy.append(len(tags.intersection(pred_tags))/len(tags.union(pred_tags)))\n",
    "        return(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3a2a4fc2a64fd59c14094d897d938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.57\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD0CAYAAABQH3cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd8VHW+//HXpFFC7yIoRfmqoCAQeiKsDcVe1saqq7tXsSK413v3J9f9ed1uUJG1oVhYK9Z1bViQhB5FRUAPoPReAwFCSDL3j5lMyUwmhZk5c2bez8eDx+PMmTOZT+ZB3vnme77F5Xa7ERERZ0izuwAREak7hbaIiIMotEVEHEShLSLiIAptEREHUWiLiDhIRqy+8I4d+zWWUESkntq3b+6K9Lxa2iIiDqLQFhFxEIW2iIiDKLRFRBxEoS0i4iAKbRERB1Foi4g4iEJbRMRBYja5pqG+21TMf73/AzsPlAFQNDHP5opERBJHwrW0f/Pad77ABnh9ySYbqxERSSwJF9pXnd456PHDs3+yqRIRkcSTcKE9fmTPkHNHKiptqEREJPEkXGhnpIWulTLs0bnk5BdQqf0sRSTFJVxoA/x26HFhzw+eXBjnSkREEosr0m7sxphMYDrQDWgEPAQsBKYBrYF04HrLskI6no92adaKSjdlFZXkTZkXdF6jSUQkmR3t0qxjgV2WZeUCo4GpwN+Aly3LygPuB06KRqHVpae5aJKZDkDjDH+ZB8rKY/F2IiKOUFtozwQmeY9dQDkwHOhijPkMuA74MmbV4WlZF949wvd45OPzY/l2IiIJLWJoW5ZVYlnWfmNMc+BNPC3rbsAey7LOAtYD98W8SuDKfp1rv0hEJMnVeiPSGNMVmA3MsCzrFWAX8C/v0+8DA2NXnt/EUf6hgJH64UVEklnE0DbGdARmAfdZljXde3oucL73OA9YHrvy/NIDhgK+VLQxHm8pIpJwahs98hhwFfBjwOkbgGeBbKAYuNayrD3VXxuLjX1z8gt8x5/dNpSWTTKj/RYiIraqbfRIxNA+GrEI7dIjFeQGDAHU8D8RSTZJtRt748x0zju5g+9xWbmmt4tIanFUaAM8eL5/WPj5Ty+0sRIRkfhzXGgHKi7VRBsRSS2ODm0RkVTjyNB+66Ycu0sQEbGFI0P7uNZN7C5BRMQWjgztQBWVmh0pIqnD8aF97pMLWLQ2ZG6PiEhScnxoF5eWc8db3/PB8m12lyIiEnOODe1Pxw0NevzWd1tsqkREJH4cG9qtmmZyjmnve/z9ln1Ba5OIiCQjx4Y2wENjYrJpjohIwnJ0aLtcrpBFow6WVQCeNbfHPL2QnPwC3l2qrhMRSQ6ODu0qRRPzGNGjDQD/WrYVgD99uortJWUA/PHTVXy4QjcqRcT5kiK0AdJcntUM82d7NoZ/9/utQc8/8JEV95pERKItaUL7P4Ye7zvWju0ikqySJrRNx2a+4ylz1viOF0/ItaMcEZGYSJrQDvS298Zj2+wsXK6Im0CIiDhKUoZ2lQ9vGRz0uFK7uIuIwyVVaFfvCqm6Odkow/NtLtAaJSLicEkV2jV1hVQNBxz/9jJitZGxiEg8JFVoA8wfPwKASef28p37r7NO9B2Pmjo/7jWJiERLht0FRFtmelrILMlWTTJ9xwe8MyZFRJwo6VraNanq1wbdkBQR50qZ0J579wjf8eDJhTZWIiLScCkT2gCDjmtldwkiIkclpUL7kUv72F2CiMhRSanQzgro1359ySYbKxERaZiUCm2AmwZ3BWDemt02VyIiUn8pF9o3DDoO0OxIEXGmlAvtplnpvmPNjhQRp0m50AZo2dgzp2iHd2cbERGnSMnQrprivr3ksM2ViIjUT0qGdrvsLACK1u+1uRIRkfpJzdBu1giAJ+autbcQEZF6SsnQ7tAsy+4SREQaJCVDW1uQiYhTpWRoB9KwPxFxkpQN7ZuHeCbZHDpSaXMlIiJ1FzG0jTGZxpgZxphCY8xiY8xFAc9da4xZEPsSY2PJxmIA/vzZKpsrERGpu9pa2mOBXZZl5QKjgakAxpjTgZsBx3YOd27ZGICPf9jO9v0ary0izlBbaM8EJnmPXUC5MaYt8CdgfCwLi7U/jDa+4zHPLLKxEhGRuou4R6RlWSUAxpjmwJt4Avw5YAJwKObViYhIkFpvRBpjugKzgRnAKuBE4EngNeAUY8yjMa0whgI3AC6v0A1JEUl8EVvaxpiOwCzgDsuyPvee7u19rhvwmmVZju4mOfWYFny/ZR/FpeW0zdakGxFJbLW1tH8PtAYmGWO+9P5rEoe64mbkCW0B+Nvnq22uRESkdrX1ad8N3F3Dc2uBITGoKa52HPAsz/rFqp02VyIiUruUnVxTZeKonr7j0iMVNlYiIlK7lA9tgCv6HgPA8q37ba5ERCQyhTbQoblnqdZb31hqcyUiIpEptIELene0uwQRkTpRaAPtvZsiAHyl3WxEJIEptKvZV3rE7hJERGqk0PZ68srTAHjn+602VyIiUjOFtleXVp5V/xau3WNzJSIiNVNoe3Vq0dh3XKndbEQkQSm0w5j47nJ2lhxmR4nW2RaRxBJxGnuqmvvzbs572r/GduBqgCIidlJLO8An48IvpbLnYFmcKxERCU+hHaBN0/BLs67fo/0eRCQxKLSr+eiWwb7jhy8+BYCsDH1MIpIY1KddTbtmjXx92F9v8MyO3F9abmdJIiI+akJGcLDMs1TrM/PX2VyJiIiHQjuCUzu3AGBHyWGemreWhz5ZaXNFIpLqXO4YTSTZsWO/42eouN1uBk0uDDqX7oKFEzQEUERio3375q5Iz6ulHYHLFfrZVbih5HDtfdwfLN/Gr1/5huJDWoBKRKJHod0Ao6bOJ9JfKEcqKvnDxxbLtuznrCcWxLEyEUl2Cu0GGjS5ELfbzYcrtpGTX8CMog2+595ZusXGykQkmSm0a7FoQq7veNpVfYOeGzS5kAc+sgCYUrAGgNU7DvD3L34Kuu6QNgwWkShRaNciLaBfu1+XliwYP6LGa2+fuZRrXvo65PziddoNR0SiQ6FdB/mX9OZ/zu0FQEZ6GtlZ6WGvWxywVdmscUMY49178t73lse+SBFJCQrtOsjr2ZYL+3TyPf7yzuFc7H2c26MNp3dpGfKa1k2zeMAb9CIi0aJp7A10/7m9uN8bytb2EsbOWAJAz3ZNGX1SByB4yOC+0iO0aJwZ/0JFJKkotKOgV/ts3/FrNwwMe82Z//AM/dPa3CJyNNQ9EgUul4vh3dswcVTPkOf+dMHJNlQkIslKoR0lj17Wh6v7Hxty/mzTPujxxr1am1tEGk6hHQfXDejiO770uaKIsylFRCJRaMfB+JE9+Oev+vsev1S00cZqRMTJFNpxYjo08x1PLVxjYyUi4mQK7TgKnE1ZVl5pYyUi4lQK7TjKSPd/3MMfmwvA2t0HeVcLTIlIHWmcto0q3W6ufP4rAMb07khmun6HikhkSgkbDQ7YFadqUakt+0rJyS9gmvalFJEwFNpxNn/8CHp3ah5yfvw7yygrr+SiaYsBeGbBOhau3R3v8kQkwWmPSJvk5BfU6TpNexdJLdojMkG9fuMA33HOca1qvG7d7oPxKEdEHCJiS9sYkwlMB7oBjYCHgPXA40AFcBi43rKsbdVfq5Z27UqPVJCVkcbh8krypszznT+rVzs+W7nT91itbZHUcbQt7bHALsuycoHRwFTgMeBOy7JGAm8D90WhzpTUODOdNJeLJpn+TRWy0l38+cJTbKxKRBJZbUP+ZgJveo9dQDlwtWVZVQOLM4DSGNWWUqq3pm8a3JXpizybBWstbhGpErGlbVlWiWVZ+40xzfGE9/1VgW2MGQbcATwS+zJTz7gR3X3HVWtxi4jUeiPSGNMVmA3MsCzrFe+5q4CngDGWZe2IbYmpa/o1/XzHOfkF7Cs9YmM1IpIIIoa2MaYjMAu4z7Ks6d5zY/G0sEdalvVz7EtMXad2bhH0WC1uEalt9MhjwFXAj95T6UAfYB1QtfX4HMuyHqj+Wo0eiY7Cn3Yx4V3/bu4aSSKS3GobPaLJNQ5wuLySEd4FpsAf3HNW7+K+91fw7s05dGrR2K7yRCSKNLkmCTTKSOP+c04MOX/ve8upqHRzoXfqu4gkP4W2Q1x86jG+4+te+poPV4TMZxKRFKDQdpDWTTxjtVfuOMADH1lBz5UeqbCjJBGJM4W2g7wWsF5JdaOfWhjHSkTELgptB2nTNCvk3Gs3eIL8QFkFt77xXbxLEpE4U2g7zF8v8q9L8silvenZLtv3+OsNxXy+UnOdRJKZthtzmF+c2I5XbxhAZaWbXgE7vFcp/Hk3Z/Zqb0NlIhIPamk70AntsoMC+40bB/qOP1i+jfzZP9lRVlx9vWEvOfkFETeTmPntZmb9uD2OVYnEnkI7CXRv2zRopuRrSzbZWE183PrGUt/xl6t2Ul7pJie/gKfmrQXA7Xbzt89X8/8++JGSw+VBr91UfIic/AKOVFTGs2SRqFBoi+Ns23846PHv/rWCP85aCcBzC9cDMGrqfN/zo6bOpzJg5u8lzxYBMOzRuYg4jUI7ibxzc47dJUTN6p0Hauza2F/qaTkPCtim7d/LgycbHSgLHrc+/u1lAFz2nGaPirPpRmQS6dKqid0lRM01L34NwDcbi/nPM0/A5fIsx1ByuJxrXvI8d+3ALixevzfkteH6uRes3RP2vDaYEKdRSzvJZGd5ti7bXq0LwUne+Gaz7/jN77Yw+Uv/CsCB3R4L1uxm9h3DIn6t2lZF1HK34jQK7SRT1S0w5plFNlfScH//YnXQ45qWPLsjtzvNGtX8x2LTgL03A1074Fg+HTfU97j6jUqRRKbQTjKB/dqRhsMlopqWCX51ySZy8guwtpX4zhVNzKNxmFDu3am573hM744AvP/bQUHX3DOyJ62a+rtEAlvvIolOoZ1kjm3prHW1F6zd7RtvPWhyYdAvmheuOz3o2rH/XBL2a0y7qi/gCelfnt7Zd371zgMAdGrRmLyebYOurW7p5n0N/yZE4kihnWSqbthVSeTWdumRCu56a1nY58YO7BLUag405fI+QY/7dWnJp7cN5f6zT+S8kzv4zt8wqKvv+OGLT+HDWwbTr0tL37nA/u6bX/22Qd+DSLwptMUWV7/4FblT5tX4/Pw1uwG4K6873doEj4oZ2q1NyPWtmmSSkZ6Gy+Vi7t0j+MuFJzO8u/86l8tF+2aNItb0/rKtNT63aO0e3vpuc43Pi8SLthtLQks37wtqORbeNTxs/288jZu5lINlFbx43em43W4GTS4Men7++BGs3F7Cja946p52Vd+gVjHAyu0l9GiXTUZaxN2Y6qXS7WZwQC3hRpsE1vv45X24861l9O7UPKT7RiQatN1YCjqtcwuKJubRvW1TwLMGR05+AXsOltlSz7rdB/lq/V5WbN0PEBLYAJnpafQ+xr/7fPXABujVoVlUAxsgzeUKuVFZ3TlP+tcqv9PbnbN8637KK9UukfhTaCexvp09ITilYA0QHD5VjlRUsnHvoZi8/84DZeTkF3DF81/5zk2bvy7omt/9oief3+4fflc0MS/uO853atGY9DQXJ4VZNRFg76EjYc8PfST0l49IrCm0k9hvhx4fcq5qW7KKSjdb95Uy7NG5XPpcEXNW74z6+58XZjedZxb4Q/v2Ed345enHJsSMxNwebTgYZsu22sZwJ/KNXklOCu0k1qF56I233CnzOFxeyZBHCoN2cb/3vRXxLI1xw7tx4+Dj4vqekXy5ehfr9xzihUXrWbp5H8/MX0tOfkHQGO6pl58KwNX9jw167c4S584+FefR2iNJbtGEXJZsKGbagnUs2VgMwH+/Hz6gKyrdpEe5z7hK0cS8oFbpTUMSJ7AD/WPu2rDnP751CG2zs3xdN4HL3y5Yu4cL+3SKR3kiamknuzSXi4HHteLpgEklhT/vDnvtuCjuMXkwYJW9hffkBj1X1WJNJPPuHhHx+TZNa+7CefCTldEuR6RGammLzzebojcrcEqBf5GnqtZ7vG8w1kdWRuT2S/VJS0UT84KGApYeqbB9WKWkBrW0U9xpnVswf7y/lXmwLPRmXEO89d0WwLP5cLIKDPLN+0ptrERSiUI7hSyekOsbBjjpnF4UTczjuWv6kZnu/2/ww7b9R/0+uw74x4P379IqwpWJ5YHRvQB489cDKZqYx20jutX6mr9ceDIAa3cdBDw3JWM1YU0ENCNSvN77fgsPzVoFHH03RuANx0TuEgmn0u0mLaAF/e3GYnof0zzoF1ugeT/vZvw7weunnGPa88cLTo5pnZK8NCNS6qRvZ/8MxKrV8QCemreWa707xdTXk1eedtR1xVtatb7rfl1a1hjYAAO6hs7c3HHAnpmnkhoU2gJAN++Ud/Bv9QWejXJX7ThQp40C3G43f//cv4HBwOOc0zXSUOFuPuakwPct9lFoS538FND6rsmgyYW88a1nJbyBYVqgyepx71KxrZt4hgUuXrfHznIkySm0xeemwf71p6976WtW7fDvFPP20i0RX1t9VuAdud2jW1wCG9KtDUUT85h1m2cNlW+jOHRSpDqFtviMG+EP2pU7DnDtS/6dYj5csT3ia9ftCV506pQaNjAQkaOj0JYgM28c2KDXZXlv1t02ohvTruobMhlFRKJDoS1BAm9IVlc1lG9hwL6O5RWVgH/50gFdW4VdCzvVrK7DPQCRhlBoS4jq23udfqx/c4In567xbQQAMPTRuQBMeHc5AE0yU/u/VIdmWQDMKNpgcyWSrFL7J0zCuj2gb3vxhFyeCBhvPX1RaBgF3oTs1qbmlnoqeGlsfwB+2FZSy5UiDaPQlhAjT2zHGzcOZME9ubhcLjLS05g4qmfQNce08K/Vfd7Ti3zHkSaipIKq1QDX7DrIbTOX2lyNJKNaV/kzxmQC04FuQCPgIWAF8ALgBpYBt1uWVRmzKiXuulfr2766/7E8u2AdxaXlnHpMc6Zfe3rIri2vXj8gniUmpMAbsEXr99pYiSSrujSLxgK7LMvKBUYDU4HJwP3ecy7g4tiVKInis9uHUTQxj+nXenYhf/WG4JA+oX22HWUltJ2a0i5RVpfQnglM8h67gHJgADDHe+4j4KzolyaJ7oR2CulwAjd9KPxpl42VSDKqNbQtyyqxLGu/MaY58CZwP+CyLKtqFb/9gMZ4paj/Pf8ku0tIOOlpLq7oewwAf/p0lc3VSLKp010jY0xXYDYww7KsV4DA/uvmgDrvUtTokzvw0S2DKbxruN2lJJSrAjb/rajUKsUSPbWGtjGmIzALuM+yrOne098YY0Z6j88DCmNTnjhBu2aNtNVWNce19o91v/+DH2ysRJJNXfaI/D3QGphkjKnq274bmGKMyQJ+wNNtIiJeaS4XZ5v2fGrtYPO+w7W/QKSOtHONSIxs33+YMc8s4t5RPYO6S0Qi0c41IjZp1sjzh+zDs3+yuRJJJgptkRhpmqV+fok+hbZIjHVp1djuEiSJ1OVGpIg00MCuLTXkT6JKoS0SQ19tKLa7BEky6h4RiYPt+zXsT6JDoS0SB2OeWVT7RSJ1oNAWiaF3bs7xHe/Sin8RPfLlT+TkF1BR6SYnv4DlW/ezubgUgMcLfiYnv4BYzStxEk2uEYmxwHXHiybm2VhJYqu+PnuV/z3/JCZ9+CMA/bu05Omr+sazrLjT5BoRm3UO2OVH6q8qsAGWbCzmiblrbKzGfgptkRh777eDfcd3v/29jZUkrppa2eE8v2gDO0oOk5NfwAfLt8WwqsSk0BaJo/lr9thdQsL5blPdhkVOOreX7/h8776kf/jYojLF+rkV2iJxMOrEdr7jj3/YbmMliec3r33nO14wfgRFE/N8/wJd1KcTJ3dsFvL6wZML2X0wdW7yKrRF4uBvF53iO5704Y8aBQGUlVcGdYs8fHFvMtKDI+kc0x6A6df0A+Clsf3Dfq1zn1wYoyrrp+RwOX/+dBX7So/E7D0U2iI2OPuJBSkf3DO/3Rz0+IwT2oZc88cLTqZoYh6ndm5R69dLhOUCPvlxO28v3cLSzfti9h4KbZE4mXOnf0u24tJyLpq22MZq7DFn9S7+8JFnNMgb32zynX+mHsP4qvbfBPjyzmG+40QYB/+Xz1YD0D47diOGFNoicdI0K51Pxg3xPd6aglPb731vOR+s2M68n3f7dvT5n3N7cXqXuu8Nft9ZJ1J413AWT8glOyuDgV09rx3zzKKE+evFhOl7jxaFtkgctWmaxRk9/d0A+0vLqXS7WbB2d0h3QbIJDNTx7yzzHZ93cod6f63Gmem4XJ45KPedeaLv/IGyiqOo0Bm0yp9InD18SW/fDbhf/GN+0HMlh8v59eDj7Cgr5raX+LsvOjVv5PtLo/rNx/rq1rap77jkcLlvx6B4Wr51Pze+/E1c3kstbREbvH7jgLDnn5i7lh+27WfO6l1xrig29hwsY0fJYe54cykXBCyaFe2uoUtO7QTAF6t2Bp1fu/tgVG5Q7j14hFFT51FyuJydB8pYuHa377mc/IKgwO5fj66ehlBLW8QGPdpm1/jc9f/0BMDCe3JJT4u4DEXCO6eWoXgzxp4elfcZ0aMt736/la37/L8Mqv6a6XdsC6Zd3e+ovv7ZTy4AYNRU/19GPds15aedB0OujfXaKGppi9jko1sGc0bPttx9Ro+wz//ls1Xk5BeQk1/A+8u2xrm6o1dyuDzk3L2jetKskX/vzJM6No/Ke7XLzgTg1SWbQobbfbsp/PC7GUUbyMkvYOPeQw16z3CBPfuOYWGujC6t8ieSIH7edYCrXvi6xuc/v30oLRpnxrGioxNuPZGqWY5T5vzM9TldadU0et9P4Pt9Om6or3UM8OzVfelzTAteXLyBJ+etDXpdepqLhffk1vh13W43gyYXRnzvRy/rw/DubRpWeDVa5U/EISJ1mUD4ll2iClwPpHubplw74FjeuHGg79xdZ/SIamBXFxjY4Jkq//yi9SGBDZ5JOZHWP5lRtLHW94tWYNeFWtoiCei+f60Iuak2okcbHrm0j00V1aysvJLhj80F4M1fD+T4Nk1tWUM8sI4qA7q25Os67NPZrFE6s+8YHva5e95Zxtyfd3OOaU+7ZlnsKClj3PBuuFzQuWVjKt2QEcV7D7W1tHUjUiQB/TVgrZKSw+WMmjqfuT/vjvAK+/zX+yt8x1c8/xX//zzje3xN/2PjVkdWRhrv3JzDpc8V+c49ceVp/O3z1bz13ZaIry05XPP47qrP/eJTOzHo+NYhz8f7XrG6R0QSnB3jjuujsNovkwc+snzHE0b1jGstXVo14eNbPbNOp15xKmkuF/eM9NdwZq92QS3/wGnwtTmtDuufxENi/28QEcca0SN+/byB2mZnBQVzo4w0FowfQVqaizTvLMq3b8qhWaN0srP8Efgfr3/H788+kW5tPJN1fvfecnq0899naJzpH/ViJ7W0RRzg/FPqP9U7HgLviVXvu06k7pyM9DRfYAN0bd2E1k2zgq75ZmMxVz7/FWXllazdfZAvV+9i+sL18S61VgptEQf4cIVn44T5axInCMEzfTvQfWeeYFMlDffqDcGzU4c/NpfF6xJ3hyGFtogD3DLseACOVFTaXEmwX7/yLeAZRQFwRb/OLJqQS/4lvevVX2ynE9pl8+D5Jujc37/4KejxggjjuONNoS3iABd719a4970VzK42FNAugWOxn/7lab7jNJeLvJ5tg/qLE915J3eMODQxmkP6jpZCW8QB2mb7+1/v+9eKCFfGz6a9pb7jTi0a21hJ7Lx+4wAWjB9hdxlBFNoiDhB4E81N+HU94qHS7aai0vPvsume8dCjG7AedqJaPMHfDZJ/SW96tM0+6qVjo00zIkUcorzSzdBH/GtgxGumYZVKt5vBYdbgeOfmHLq0ahLXWpKZ1h4RSRIZaS6Oa133cNy+/3DI9lsb9x5izuqG9Yl/sHxb2PMdmsVuP0QJpdAWcZC3bsrxHT9esCbk+U3Fh/jM2sGsH7cz5plFDJpcyJinF7JyewkAlz5XxL3vreDZBetqfa+y8uCRKg9+sjLkmrvyupOVoRiJJ+fc3hWRIC8VbeDOvO4A/PnTVby9NPz6GttLyrhuxhLm3u2/ofb0/HX8ZujxNX7t22cuZfH6vcwYezo922Wzubg05JrrBnThVzldj/K7kPpSn7aIw+w5WObbEaaqXzvc2tV1cUHvjjww2vDhim2+NUMWT8iNuH500cQ8NhUf4tiW6seOBfVpiySZwOnXOfkFlB/FhJt/L9/GonV7ghZ5+uvnq2t9nQLbPnVqaRtjBgN/tSxrpDGmH/AUUA6sBH5jWVbI/xq1tEVi5+WvNvLonJ9DzocbUVJ91MnLv+rPdTOWNOh94z1iJRUddUvbGPOfwLNA1ej5B4AHLcsaATQCxhxtkSJSP9cN7FLnazPSXFzUp6Pvca8Ozer0uuysdC7vewxFE/MYcnxr8i/pXe86JfrqciPyJ+AyYIb38TdAG2OMC2gOHIlRbSISwcJ7chkS0II2EcJ40rmGy/p25pgWnuF5VS3mFxdvYGqhZxTK2zflcPOr37LnkOdH+os7hvkm9Tx+xakx+R6k/mptaVuW9RbBwbwKmAL8AHQEvoxJZSISUXqai6KJebz8q/6c0C6bqZdHDtbenZrTptpypDcM8o/+aN00k0/GDeHxy/uw8J7coFmYkjjq2qfdDXjNsqwhxpjtwCjLspYbY24HTrEs6/bqr1GftogzVLrdFB86ErK+tNgjFqNHdgP7vMebgdBN00TEMdJcLgW2gzRkcs1vgNeMMeVAGfDb6JYkIiI10eQaEZEEosk1IiJJRKEtIuIgCm0REQdRaIuIOIhCW0TEQWI2ekRERKJPLW0REQdRaIuIOIhCW0TEQVJij0hjTCYwHeiGZw3wh4AVwAuAG1gG3G5ZVqUx5gE8a4SXA+Mty1psjDmhrtfG8/s6WsaYDsDXwNl4vocXSNHPwxjz38BFQBbwBDCHFPw8vD8rL+L5WanAs0xFSv7fqLb5S52/r2hcG6muVGlpjwV2WZaVC4wGpgKTgfu951zAxcaY/sAZwGDgauAf3tfX51pH8P5wPg0c8p5K2c/DGDMSGAYMx/M9dCV1P4/zgQzD35CxAAACG0lEQVTLsoYBDwJ/JAU/izCbv8TqMwi5trbaUiW0ZwKTvMcuPL/pBuBpTQF8BJwFjABmWZbltixrPZBhjGlfz2ud4mE828Zt9j5O5c/jXOB74B3gfeDfpO7nsRJPrWlACzxr6afiZ1G1+UuVWH0G4a6NKCVC27KsEsuy9htjmgNvAvcDLsuyqsY77gda4vlPWhzw0qrz9bk24RljbgR2WJb1ScDplP08gHbAQOBK4FbgZSAtRT+PEjxdIz8C0/BseJJy/zfCbP4Sq88g3LURpURoAxhjugKzgRmWZb0CBPYbNQf24lknvHmY8/W51gluAs42xnwJ9ANeAjoEPJ9qn8cu4BPLssosy7KAUoJ/eFLp87gHz2fRC+iLp387cLHtVPosAsUqL8JdG1FKhLYxpiMwC7jPsqzp3tPfePsyAc4DCoF5wLnGmDRjzHF4Wls763ltwrMsK8+yrDMsyxoJfAtcD3yUqp8HMBcYbYxxGWM6A9nA5yn6eezB3yLcDWSSwj8rAWL1GYS7NqKUGD0C/B7PDjuTjDFVfdt3A1OMMVl49rt807KsCmNMIbAAzy+0qm3UJgLT6nitU9Xne0yqz8OyrH8bY/KAxfhrX0Nqfh6PANO9tWfh+dn5itT8LALF6ucj5NraCtE0dhERB0mJ7hERkWSh0BYRcRCFtoiIgyi0RUQcRKEtIuIgCm0REQdRaIuIOIhCW0TEQf4POBYVvT9SBRcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121d2a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "android : android, activity, quot, 04, exampleproguard\n",
      "ios : ios, uiview, dylib, nil, nsstring\n",
      "python : python, def, py, django, np\n",
      "jquery : jquery, ready, ajax, li, val\n",
      "html : 3, br, amp, html, span\n",
      "c++ : avrf, c++, std, cout, cpp\n",
      "c# : writeline, binding, runat, linq, foreach\n",
      "php : php, x5c, _post, echo, 125\n",
      "javascript : javascript, 3, 125, js, getelementbyid\n",
      "java : println, servlet, spring, hibernate, java\n"
     ]
    }
   ],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
